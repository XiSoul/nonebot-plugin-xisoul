import httpx
import re
from bs4 import BeautifulSoup
from typing import Dict, Optional, List, Any
from nonebot import logger

class HuangLiScraper:
    """
    é»„å†ç½‘é¡µæŠ“å–å™¨ï¼Œç”¨äºä»æŒ‡å®šURLè·å–é»„å†æ•°æ®
    """
    
    # åŸºç¡€URL
    BASE_URL = "https://www.huangli123.net/huangli/{date}.html"
    
    @staticmethod
    async def fetch_huangli_data(date: str) -> Optional[Dict[str, Any]]:
        """
        ä»ç½‘é¡µè·å–æŒ‡å®šæ—¥æœŸçš„é»„å†æ•°æ®
        
        Args:
            date: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º YYYY-MM-DD
            
        Returns:
            åŒ…å«é»„å†æ•°æ®çš„å­—å…¸ï¼Œå¦‚æœè·å–å¤±è´¥åˆ™è¿”å›None
        """
        # æ„å»ºå®Œæ•´URL
        url = HuangLiScraper.BASE_URL.format(date=date)
        logger.info(f"æ­£åœ¨è¯·æ±‚é»„å†æ•°æ®: {url}")
        
        try:
            # å‘é€HTTPè¯·æ±‚
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.get(url)
                response.raise_for_status()
                
                # è§£æHTMLå†…å®¹
                html_content = response.text
                return HuangLiScraper.parse_html_content(html_content, date)
                
        except httpx.HTTPStatusError as e:
            logger.error(f"HTTPè¯·æ±‚é”™è¯¯: {str(e)}")
        except httpx.RequestError as e:
            logger.error(f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {str(e)}")
        except Exception as e:
            logger.error(f"è§£æé»„å†æ•°æ®å¤±è´¥: {str(e)}")
        
        return None
    
    @staticmethod
    def parse_html_content(html_content: str, date: str) -> Dict[str, Any]:
        """
        è§£æHTMLå†…å®¹ï¼Œæå–é»„å†æ•°æ®
        
        Args:
            html_content: HTMLå†…å®¹å­—ç¬¦ä¸²
            date: è¯·æ±‚çš„æ—¥æœŸ
            
        Returns:
            è§£æåçš„é»„å†æ•°æ®å­—å…¸
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        result = {
            'date': date,
            'basic_info': {},
            'wu_xing': {},
            'chong_he': {},
            'san_sha': {},
            'qi_sha': {},
            'ji_xiong': {},
            'gua_xiang': {},
            'yue_ling': {},
            'tian_shen': {},
            'er_shi_ba_xiu': {},
            'di_mu_jing': {},
            'errors': []
        }
        
        try:
            # æå–åŸºç¡€ä¿¡æ¯ - æ˜Ÿå®¿
            xiu_element = soup.find(text=re.compile('ä»Šæ—¥æ˜Ÿå®¿'))
            if xiu_element and xiu_element.parent:
                xiu_text = xiu_element.parent.get_text()
                xiu_match = re.search(r'ä»Šæ—¥æ˜Ÿå®¿ï¼š\\s*([^çš„]+)', xiu_text)
                if xiu_match:
                    result['basic_info']['star'] = xiu_match.group(1).strip()
            
            # æå–äº”è¡Œä¿¡æ¯
            wu_xing_elements = soup.find_all(text=re.compile('[å¹´æœˆæ—¥]äº”è¡Œ'))
            for element in wu_xing_elements:
                if element.parent:
                    wu_xing_text = element.parent.get_text()
                    if 'å¹´äº”è¡Œ' in wu_xing_text:
                        match = re.search(r'å¹´äº”è¡Œï¼š([^\s]+)', wu_xing_text)
                        if match:
                            result['wu_xing']['year'] = match.group(1).strip()
                    elif 'æœˆäº”è¡Œ' in wu_xing_text:
                        match = re.search(r'æœˆäº”è¡Œï¼š([^\s]+)', wu_xing_text)
                        if match:
                            result['wu_xing']['month'] = match.group(1).strip()
                    elif 'æ—¥äº”è¡Œ' in wu_xing_text:
                        match = re.search(r'æ—¥äº”è¡Œï¼š([^\s]+)', wu_xing_text)
                        if match:
                            result['wu_xing']['day'] = match.group(1).strip()
            
            # æå–å†²åˆä¿¡æ¯
            chong_he_element = soup.find(text=re.compile('ä»Šæ—¥å†²åˆ'))
            if chong_he_element and chong_he_element.parent:
                chong_he_text = chong_he_element.parent.get_text()
                result['chong_he']['info'] = chong_he_text.replace('ä»Šæ—¥å†²åˆ', '').strip()
            
            # æå–ä¸‰ç…æ–¹ä¿¡æ¯
            san_sha_elements = soup.find_all(text=re.compile('ä¸‰ç…'))
            for element in san_sha_elements:
                if element.parent:
                    san_sha_text = element.parent.get_text()
                    if 'æœ¬å¹´ä¸‰ç…' in san_sha_text:
                        match = re.search(r'æœ¬å¹´ä¸‰ç…ï¼š([^;]+)', san_sha_text)
                        if match:
                            result['san_sha']['year'] = match.group(1).strip()
                    elif 'æœ¬æœˆä¸‰ç…' in san_sha_text:
                        match = re.search(r'æœ¬æœˆä¸‰ç…ï¼š([^;]+)', san_sha_text)
                        if match:
                            result['san_sha']['month'] = match.group(1).strip()
                    elif 'ä»Šæ—¥ä¸‰ç…' in san_sha_text:
                        match = re.search(r'ä»Šæ—¥ä¸‰ç…ï¼š([^;]+)', san_sha_text)
                        if match:
                            result['san_sha']['day'] = match.group(1).strip()
            
            # æå–ä¸ƒç…æ–¹ä¿¡æ¯
            qi_sha_elements = soup.find_all(text=re.compile('ä¸ƒç…'))
            for element in qi_sha_elements:
                if element.parent:
                    qi_sha_text = element.parent.get_text()
                    if 'å¹´ä¸ƒç…' in qi_sha_text:
                        match = re.search(r'å¹´ä¸ƒç…ï¼š([^\s]+)', qi_sha_text)
                        if match:
                            result['qi_sha']['year'] = match.group(1).strip()
                    elif 'æœˆä¸ƒç…' in qi_sha_text:
                        match = re.search(r'æœˆä¸ƒç…ï¼š([^\s]+)', qi_sha_text)
                        if match:
                            result['qi_sha']['month'] = match.group(1).strip()
                    elif 'æ—¥ä¸ƒç…' in qi_sha_text:
                        match = re.search(r'æ—¥ä¸ƒç…ï¼š([^\s]+)', qi_sha_text)
                        if match:
                            result['qi_sha']['day'] = match.group(1).strip()
            
            # æå–ä¹æ˜Ÿå‰å‡¶ä¿¡æ¯
            jiu_xing_element = soup.find(text=re.compile('ä»Šæ—¥æ²³å›¾æ´›ä¹¦ä¹æ˜Ÿå‰å‡¶'))
            if jiu_xing_element:
                jiu_xing_div = jiu_xing_element.find_parent(['div', 'p'])
                if jiu_xing_div:
                    result['ji_xiong']['nine_star'] = jiu_xing_div.get_text().replace('ä»Šæ—¥æ²³å›¾æ´›ä¹¦ä¹æ˜Ÿå‰å‡¶', '').strip()
            
            # æå–å¦è±¡ä¿¡æ¯
            gua_xiang_element = soup.find(text=re.compile('ä»Šæ—¥å¦è±¡'))
            if gua_xiang_element and gua_xiang_element.parent:
                gua_xiang_div = gua_xiang_element.find_parent(['div', 'p'])
                if gua_xiang_div:
                    result['gua_xiang']['info'] = gua_xiang_div.get_text().replace('ä»Šæ—¥å¦è±¡ï¼š', '').strip()
                    
                    # æŸ¥æ‰¾å¦è±¡è¯¦ç»†æè¿°
                    next_element = gua_xiang_div.find_next(['div', 'p'])
                    if next_element:
                        gua_desc = []
                        current = next_element
                        while current and not any(keyword in current.get_text() for keyword in ['æœˆä»¤', 'ç‰©å€™', 'ä»Šæ—¥åäºŒç¥', 'äºŒåå…«æ˜Ÿå®¿']):
                            gua_desc.append(current.get_text().strip())
                            current = current.find_next(['div', 'p'])
                        result['gua_xiang']['description'] = '\n'.join(gua_desc)
            
            # æå–æœˆä»¤ã€ç‰©å€™ç­‰ä¿¡æ¯
            yue_ling_element = soup.find(text=re.compile('æœˆä»¤'))
            if yue_ling_element and yue_ling_element.parent:
                yue_ling_text = yue_ling_element.parent.get_text()
                match = re.search(r'æœˆä»¤ï¼š\\s*([^\s]+)', yue_ling_text)
                if match:
                    result['yue_ling']['month'] = match.group(1).strip()
            
            wu_hou_element = soup.find(text=re.compile('ç‰©å€™'))
            if wu_hou_element and wu_hou_element.parent:
                wu_hou_text = wu_hou_element.parent.get_text()
                match = re.search(r'ç‰©å€™ï¼š\\s*([^\s]+)', wu_hou_text)
                if match:
                    result['yue_ling']['phenology'] = match.group(1).strip()
            
            # æå–åäºŒç¥å‰å‡¶ä¿¡æ¯
            er_shi_shen_element = soup.find(text=re.compile('ä»Šæ—¥åäºŒç¥å‰å‡¶æ‰€ä¸»'))
            if er_shi_shen_element and er_shi_shen_element.parent:
                er_shi_shen_div = er_shi_shen_element.find_parent(['div', 'p'])
                if er_shi_shen_div:
                    result['tian_shen']['twelve_gods'] = er_shi_shen_div.get_text().replace('ä»Šæ—¥åäºŒç¥å‰å‡¶æ‰€ä¸»', '').strip()
            
            # æå–äºŒåå…«æ˜Ÿå®¿å‰å‡¶ä¿¡æ¯
            er_shi_ba_xiu_element = soup.find(text=re.compile('ä»Šæ—¥äºŒåå…«æ˜Ÿå®¿å‰å‡¶'))
            if er_shi_ba_xiu_element and er_shi_ba_xiu_element.parent:
                er_shi_ba_xiu_div = er_shi_ba_xiu_element.find_parent(['div', 'p'])
                if er_shi_ba_xiu_div:
                    result['er_shi_ba_xiu']['info'] = er_shi_ba_xiu_div.get_text().replace('ä»Šæ—¥äºŒåå…«æ˜Ÿå®¿å‰å‡¶', '').strip()
            
            # æå–åœ°æ¯ç»ä¿¡æ¯
            di_mu_jing_element = soup.find(text=re.compile('åœ°æ¯ç»åœæ›°'))
            if di_mu_jing_element:
                # æå–åœæ›°å†…å®¹
                div_element = di_mu_jing_element.find_parent(['div', 'p'])
                if div_element:
                    result['di_mu_jing']['divination'] = div_element.get_text().replace('åœ°æ¯ç»åœæ›°', '').strip()
                    
                    # æå–è¯—æ›°å†…å®¹
                    shi_yue_element = soup.find(text=re.compile('åœ°æ¯ç»è¯—æ›°'))
                    if shi_yue_element and shi_yue_element.parent:
                        result['di_mu_jing']['poem'] = shi_yue_element.parent.get_text().replace('åœ°æ¯ç»è¯—æ›°', '').strip()
            
        except Exception as e:
            logger.error(f"è§£æHTMLå†…å®¹æ—¶å‡ºé”™: {str(e)}")
            result['errors'].append(str(e))
        
        return result
    
    @staticmethod
    def format_huangli_data(huangli_data: Dict[str, Any]) -> List[str]:
        """
        æ ¼å¼åŒ–é»„å†æ•°æ®ä¸ºå¯è¯»æ–‡æœ¬åˆ—è¡¨
        
        Args:
            huangli_data: é»„å†æ•°æ®å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬åˆ—è¡¨
        """
        messages = []
        
        # æ·»åŠ æ ‡é¢˜
        messages.append(f"ğŸ“… {huangli_data['date']} é»„å†ä¿¡æ¯")
        messages.append("=" * 30)
        
        # åŸºç¡€ä¿¡æ¯
        if huangli_data['basic_info'].get('star'):
            messages.append(f"â­ ä»Šæ—¥æ˜Ÿå®¿ï¼š{huangli_data['basic_info']['star']}")
        
        # äº”è¡Œä¿¡æ¯
        if huangli_data['wu_xing']:
            messages.append("\nğŸ”¥ äº”è¡Œä¿¡æ¯")
            if huangli_data['wu_xing'].get('year'):
                messages.append(f"å¹´äº”è¡Œï¼š{huangli_data['wu_xing']['year']}")
            if huangli_data['wu_xing'].get('month'):
                messages.append(f"æœˆäº”è¡Œï¼š{huangli_data['wu_xing']['month']}")
            if huangli_data['wu_xing'].get('day'):
                messages.append(f"æ—¥äº”è¡Œï¼š{huangli_data['wu_xing']['day']}")
        
        # å†²åˆä¿¡æ¯
        if huangli_data['chong_he'].get('info'):
            messages.append("\nâš–ï¸ å†²åˆä¿¡æ¯")
            messages.append(huangli_data['chong_he']['info'])
        
        # ä¸‰ç…æ–¹
        if huangli_data['san_sha']:
            messages.append("\nâš ï¸ ä¸‰ç…æ–¹ä½")
            if huangli_data['san_sha'].get('year'):
                messages.append(f"å¹´ä¸‰ç…ï¼š{huangli_data['san_sha']['year']}")
            if huangli_data['san_sha'].get('month'):
                messages.append(f"æœˆä¸‰ç…ï¼š{huangli_data['san_sha']['month']}")
            if huangli_data['san_sha'].get('day'):
                messages.append(f"æ—¥ä¸‰ç…ï¼š{huangli_data['san_sha']['day']}")
        
        # ä¸ƒç…æ–¹
        if huangli_data['qi_sha']:
            messages.append("\nğŸ’€ ä¸ƒç…æ–¹ä½")
            if huangli_data['qi_sha'].get('year'):
                messages.append(f"å¹´ä¸ƒç…ï¼š{huangli_data['qi_sha']['year']}")
            if huangli_data['qi_sha'].get('month'):
                messages.append(f"æœˆä¸ƒç…ï¼š{huangli_data['qi_sha']['month']}")
            if huangli_data['qi_sha'].get('day'):
                messages.append(f"æ—¥ä¸ƒç…ï¼š{huangli_data['qi_sha']['day']}")
        
        # ä¹æ˜Ÿå‰å‡¶
        if huangli_data['ji_xiong'].get('nine_star'):
            messages.append("\nğŸ”® ä¹æ˜Ÿå‰å‡¶")
            messages.append(huangli_data['ji_xiong']['nine_star'])
        
        # å¦è±¡ä¿¡æ¯
        if huangli_data['gua_xiang'].get('info'):
            messages.append("\nğŸ§© ä»Šæ—¥å¦è±¡")
            messages.append(huangli_data['gua_xiang']['info'])
            if huangli_data['gua_xiang'].get('description'):
                messages.append("\n" + huangli_data['gua_xiang']['description'])
        
        # æœˆä»¤ã€ç‰©å€™ç­‰ä¿¡æ¯
        if huangli_data['yue_ling']:
            messages.append("\nğŸŒ¿ æ—¶èŠ‚ä¿¡æ¯")
            if huangli_data['yue_ling'].get('month'):
                messages.append(f"æœˆä»¤ï¼š{huangli_data['yue_ling']['month']}")
            if huangli_data['yue_ling'].get('phenology'):
                messages.append(f"ç‰©å€™ï¼š{huangli_data['yue_ling']['phenology']}")
        
        # åäºŒç¥å‰å‡¶
        if huangli_data['tian_shen'].get('twelve_gods'):
            messages.append("\nğŸ‘¼ åäºŒç¥å‰å‡¶")
            messages.append(huangli_data['tian_shen']['twelve_gods'])
        
        # äºŒåå…«æ˜Ÿå®¿å‰å‡¶
        if huangli_data['er_shi_ba_xiu'].get('info'):
            messages.append("\nâœ¨ äºŒåå…«æ˜Ÿå®¿å‰å‡¶")
            messages.append(huangli_data['er_shi_ba_xiu']['info'])
        
        # åœ°æ¯ç»ä¿¡æ¯
        if huangli_data['di_mu_jing']:
            messages.append("\nğŸ“œ åœ°æ¯ç»")
            if huangli_data['di_mu_jing'].get('divination'):
                messages.append("åœæ›°ï¼š")
                messages.append(huangli_data['di_mu_jing']['divination'])
            if huangli_data['di_mu_jing'].get('poem'):
                messages.append("\nè¯—æ›°ï¼š")
                messages.append(huangli_data['di_mu_jing']['poem'])
        
        # é”™è¯¯ä¿¡æ¯
        if huangli_data.get('errors'):
            messages.append("\nâŒ æ•°æ®è§£æè­¦å‘Š")
            for error in huangli_data['errors']:
                messages.append(f"- {error}")
        
        return messages
